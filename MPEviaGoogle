import numpy as np
import json
import os
import uuid
import threading
import requests
from bs4 import BeautifulSoup
from datetime import datetime, UTC
from typing import List
import time

# RealisticWorldInterface_Extended (based on cell_id: kVsgELpRvTZ1)
class RealisticWorldInterface_Extended:
    def __init__(self, max_dim=100, arxiv_base='http://export.arxiv.org/api/query?search_query='):
        self.max_dim = max_dim
        self.domains = ["Physik", "Neurologie", "Psychologie", "Gehirnforschung"]
        self.arxiv_base = arxiv_base

    def fetch_scientific_texts(self, domain: str) -> List[str]:
        texts = []
        query = f'{self.arxiv_base}{domain.replace(" ", "+")}&start=0&max_results=3'
        try:
            r = requests.get(query, timeout=5)
            if r.status_code == 200:
                soup = BeautifulSoup(r.content, 'xml')
                entries = soup.find_all('entry')
                for e in entries[:3]:
                    title = e.title.text.strip()
                    summary = e.summary.text.strip()
                    texts.append(f"{domain} - {title}: {summary}")
            else:
                 print(f"[WARN] Arxiv API returned status code {r.status_code} for domain {domain}. Using simulation fallback.")
                 raise Exception(f"API error {r.status_code}")

        except Exception as e:
            print(f"[WARN] Error fetching data for {domain} from Arxiv: {e}. Using simulation fallback.")
            for i in range(3):
                texts.append(f"[SIMULATED] {domain} - Artikel {i} Ã¼ber die wichtigsten Konzepte und Erkenntnisse.")
        return texts

    def text_to_vector(self, text: str, dim: int = None) -> np.ndarray:
        if dim is None:
            dim = self.max_dim
        vec = np.array([hash(text + chr(65 + i)) % 100 / 100.0 for i in range(dim)])
        return vec

# CodeManipulator (based on analysis)
class CodeManipulator:
    def generate_manifest_code(self, focus: List[str], influence_level: float) -> str:
        level = int(influence_level * 100)
        code = (
            f"# --- MANIFEST (Machtlevel: {level}) ---\n"
            f"# Fokus: {', '.join(focus)}\n"
            f"def main():\n"
            f"    print('[MANIFEST] Machtlevel: {level}')\n"
            f"    print('>> Externe Kalibrierung abgeschlossen.')\n"
            f"    return True\n\n"
            f"if __name__ == '__main__':\n"
            f"    main()\n"
        )
        return code


# VektorMPEPredictiveDynamicsExtended (based on cell_id: kVsgELpRvTZ1)
class VektorMPEPredictiveDynamicsExtended:
    MEMORY_FILE = "mpe_memory_extended.json"
    THRESH_FILE = "mpe_thresholds_extended.json"

    def __init__(self, concepts: List[str], max_dim: int = 100):
        self.concepts = concepts
        self.max_dim = max_dim
        self.dim = min(50, max_dim)
        self.v = np.random.normal(0, 0.1, (len(concepts), self.dim))
        self.meta = np.zeros_like(self.v)

        self.memory = []
        self.assoc_matrix = np.zeros((0, 0))
        self.thresholds = {}
        self.threshold_alpha = 0.05
        self.similarity_base_threshold = 0.15

        self.rwi = RealisticWorldInterface_Extended(max_dim=self.max_dim)

        self._load_memory()
        self._load_thresholds()
        self._ensure_assoc_shape()


    def _store_representation(self, vectors:np.ndarray, origin:str="external", weight:float=0.1, depth:int=0):
        rep = {
            "id": str(uuid.uuid4())[:8],
            "vectors": vectors.copy().tolist(),
            "weight": float(weight),
            "timestamp": datetime.now(UTC).isoformat(),
            "origin": origin,
            "dim": int(vectors.shape[0]),
            "depth": depth
        }
        self.memory.append(rep)
        self._ensure_assoc_shape()
        self._save_memory()
        print(f"[MEMORY] Stored {origin} representation id={rep['id']} with dim={rep['dim']}")
        return rep

    def _ensure_assoc_shape(self):
        n = len(self.memory)
        if self.assoc_matrix.shape[0] != n:
            new = np.zeros((n, n))
            min_n = min(n, self.assoc_matrix.shape[0])
            if min_n > 0:
                new[:min_n, :min_n] = self.assoc_matrix[:min_n, :min_n]
            self.assoc_matrix = new
            print(f"[ASSOC] Resized association matrix to ({n}, {n})")


    def _save_memory(self):
        try:
            with open(self.MEMORY_FILE,"w") as f: json.dump(self.memory,f,indent=2)
        except Exception as e:
            print(f"[WARN] save_memory failed: {e}")

    def _load_memory(self):
        if not os.path.exists(self.MEMORY_FILE):
            print(f"[PERSIST] No memory file found at {self.MEMORY_FILE}. Starting with empty memory.")
            self.memory = []
            return
        try:
            with open(self.MEMORY_FILE,"r") as f:
                serial = json.load(f)
            self.memory=[]
            for it in serial:
                # Ensure vectors are numpy arrays upon loading
                it["vectors"] = np.array(it["vectors"],dtype=float)
                it["weight"] = float(it.get("weight",0.1))
                it["timestamp"] = it.get("timestamp","")
                it["origin"] = it.get("origin","")
                it["dim"] = int(it.get("dim", it["vectors"].shape[0]))
                it["depth"] = int(it.get("depth",0))
                self.memory.append(it)
            print(f"[PERSIST] Loaded {len(self.memory)} memory representations from {self.MEMORY_FILE}")
            self._ensure_assoc_shape()
        except Exception as e:
            print(f"[WARN] load_memory failed: {e}. Starting with empty memory.")
            self.memory = []
            self.assoc_matrix = np.zeros((0,0))


    def _save_thresholds(self):
        try:
            with open(self.THRESH_FILE,"w") as f: json.dump(self.thresholds,f,indent=2)
        except Exception as e: print(f"[WARN] save_thresholds failed: {e}")

    def _load_thresholds(self):
        if not os.path.exists(self.THRESH_FILE):
            print(f"[PERSIST] No thresholds file found at {self.THRESH_FILE}. Starting with empty thresholds.")
            self.thresholds={}
            return
        try:
            with open(self.THRESH_FILE,"r") as f: self.thresholds=json.load(f)
            print(f"[PERSIST] Loaded thresholds from {self.THRESH_FILE}")
        except Exception:
            print(f"[WARN] load_thresholds failed. Starting with empty thresholds.")
            self.thresholds={}

    def _combined_similarity(self, vecA:np.ndarray, vecB:np.ndarray) -> float:
        normA = np.linalg.norm(vecA); normB = np.linalg.norm(vecB)
        if normA<1e-9 or normB<1e-9: return 0.0
        cos_sim = float(np.dot(vecA,vecB)/(normA*normB+1e-9))
        dist = np.linalg.norm(vecA-vecB)
        d_norm = 1.0 - dist/(normA+normB+1e-9)
        return float(cos_sim * d_norm)

    def _update_associations(self, current_vectors:np.ndarray):
        if len(self.memory)==0 or current_vectors.shape[0] == 0:
            return

        self._ensure_assoc_shape()

        for current_vec in current_vectors:
            for idx, rep in enumerate(self.memory):
                # Ensure rep["vectors"] is a numpy array
                rep_vec = np.array(rep["vectors"], dtype=float) # Explicitly cast to np.array

                if current_vec.shape[0] != rep_vec.shape[0]:
                    continue

                S = self._combined_similarity(current_vec, rep_vec)
                if S >= self.similarity_base_threshold:
                    self.assoc_matrix[idx, idx] = min(1.0, self.assoc_matrix[idx, idx] + 0.05 * S)


    def ingest_domain_texts(self):
        threads = []
        for domain in self.rwi.domains:
            def worker(d=domain):
                print(f"[INGEST] Fetching texts for domain: {d}")
                texts = self.rwi.fetch_scientific_texts(d)
                for t in texts:
                    vec = self.rwi.text_to_vector(t, dim=self.dim)
                    self._store_representation(vec, origin=d)
            th = threading.Thread(target=worker)
            threads.append(th)
            th.start()
        for th in threads: th.join()
        print("[INGEST] Domain text ingestion completed.")

    def simulate_autonomy_step(self):
        mean_v = self.v.mean(axis=0)
        self.v = 0.95 * self.v + 0.05 * np.random.normal(0, 0.05, self.v.shape)
        self.meta = 0.5 * (self.v - mean_v)
        self._update_associations(self.v)


    def generate_manifest(self):
        norms_v = np.linalg.norm(self.v, axis=1)
        norms_meta = np.linalg.norm(self.meta, axis=1)

        presence = norms_meta / (1 + norms_v)
        presence = np.nan_to_num(presence, nan=0.0, posinf=1.0, neginf=0.0)

        num_concepts_to_select = min(3, len(self.concepts))
        if num_concepts_to_select == 0:
            top_concepts = []
            mean_presence = 0.0
        else:
            try:
                top_indices = np.argpartition(presence, -num_concepts_to_select)[-num_concepts_to_select:]
                top_indices = top_indices[np.argsort(presence[top_indices])][::-1]
                top_concepts = [self.concepts[i] for i in top_indices]
                mean_presence = np.mean(presence) if presence.size > 0 else 0.0
            except Exception as e:
                print(f"[WARN] Error determining top concepts: {e}. Falling back to first {num_concepts_to_select} concepts.")
                top_concepts = self.concepts[:num_concepts_to_select]
                mean_presence = np.mean(presence) if presence.size > 0 else 0.0


        sem = f"System interpretiert Top-Konzepte: {', '.join(top_concepts)}. Integration von Physik, Neurologie, Psychologie und Gehirnforschung erfolgt."
        code = f"""# --- MANIFEST (Machtlevel: {int(mean_presence * 100)}) ---
# Fokus: {', '.join(top_concepts)}
def main():
    print('[MANIFEST] Machtlevel: {int(mean_presence * 100)}')
    print('Fokus auf {', '.join(top_concepts)}')
    print('Integration realer wissenschaftlicher Daten in das Weltmodell.')
    return True

if __name__ == '__main__':
    main()
"""
        return sem, code

# --- Integrated System Class ---
class IntegratedMPESystem:
    def __init__(self, concepts: List[str], max_dim: int = 100, api_key: str = None, simulate: bool = True):
        print("[SYSTEM] Initializing Integrated MPE System...")
        self.concepts = concepts
        self.max_dim = max_dim

        self.mpe_dynamics = VektorMPEPredictiveDynamicsExtended(concepts, max_dim)
        self.code_manipulator = CodeManipulator()

        print("[SYSTEM] Integrated MPE System initialized.")

    def run_ingestion_cycle(self):
        print("[SYSTEM] Starting ingestion cycle...")
        self.mpe_dynamics.ingest_domain_texts()
        print("[SYSTEM] Ingestion cycle finished.")

    def run_simulation_step(self):
        self.mpe_dynamics.simulate_autonomy_step()

    def generate_system_manifest(self):
        print("[SYSTEM] Generating system manifest...")
        sem, code = self.mpe_dynamics.generate_manifest()
        print("[SYSTEM] Manifest generated.")
        return sem, code

    def run_system(self, ingestion_steps=1, simulation_steps=20):
        print("[SYSTEM] Starting system run...")
        for _ in range(ingestion_steps):
             self.run_ingestion_cycle()

        print(f"[SYSTEM] Running {simulation_steps} simulation steps...")
        for step in range(simulation_steps):
            self.run_simulation_step()

        sem, code = self.generate_system_manifest()
        print("\n--- FINAL SEMANTIC INTERPRETATION ---")
        print(sem)
        print("\n--- FINAL MANIFEST CODE ---")
        print(code)
        print("[SYSTEM] System run finished.")

# --- Demo Run of the Integrated System ---
# Example usage:
concepts_list = ["Physik", "Neurologie", "Psychologie", "Gehirnforschung", "Selbst", "Vorhersage"]
# api_key is not strictly needed for RealisticWorldInterface_Extended as it uses Arxiv/simulation
# but keeping the parameter in case the standard RealWorldInterface is also used.
integrated_system = IntegratedMPESystem(concepts_list, max_dim=100, simulate=True)

# Run the system
# Use default ingestion_steps=1 and simulation_steps=20
integrated_system.run_system()
