# aktualisiertes_mpe_vektor_dynamics.py
import numpy as np
import pandas as pd
import time
import os
import random
import pyttsx3
import json
from typing import List, Tuple
from datetime import datetime

# Optional: Nur aktivieren, wenn echte API-Calls gewollt
import openai

# ==============================================================================
# 1. REAL-WORLD INTERFACE (digitale Sensorik & API)
# ==============================================================================

class RealWorldInterface:
    def __init__(self, api_key: str, simulate: bool = True, tts_enabled: bool = False, max_api_calls: int = 50):
        openai.api_key = api_key
        self.simulate = simulate
        self.api_call_count = 0
        self.max_api_calls = max_api_calls
        self.expected_universal_state = np.array([0.5, 0.5, 0.5])

        self.tts_enabled = tts_enabled
        self.tts_available = False
        if self.tts_enabled:
            try:
                self.tts_engine = pyttsx3.init()
                self.tts_available = True
            except Exception as e:
                print(f"[WARNUNG] TTS konnte nicht initialisiert werden: {e}")

    def _safe_openai_call(self, messages, max_tokens=20):
        if self.simulate:
            time.sleep(random.uniform(0.05, 0.15))
            return {"choices": [{"message": {"content": "ok"}}], "usage": {"total_tokens": 10}}
        if self.api_call_count >= self.max_api_calls:
            raise RuntimeError("API-Aufrufbudget überschritten!")
        self.api_call_count += 1
        return openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=max_tokens
        )

    def get_real_digital_metrics(self, prompt: str, complexity_factor: float) -> np.ndarray:
        start = time.time()
        error_rate, token_cost = 0.0, 0.0
        try:
            response = self._safe_openai_call(
                [{"role": "system", "content": "Antworte kurz mit 'ok'."},
                 {"role": "user", "content": prompt}],
                max_tokens=20
            )
            latency = time.time() - start
            token_cost = response.get("usage", {}).get("total_tokens", 0)
        except Exception as e:
            latency = time.time() - start
            error_rate = 1.0

        return np.array([
            latency * 10,
            (token_cost / 50.0) * (1 + complexity_factor),
            error_rate * 50 * (1 + complexity_factor)
        ])

    def get_google_search_info(self, query: str) -> np.ndarray:
        # zurückgegebene Dim muss mit current dim kompatibel gemacht werden außerhalb
        # Wir liefern standardmäßig 3-dim Werte; die Aufrufer passen sie bei Bedarf an.
        return np.array([0.1, 0.6, 0.3]) * random.uniform(0.9, 1.1)

    def interpret_vectors_semantically(self, relevant_concepts: List[str], avg_error: float,
                                       avg_presence: float, user_input: str) -> str:
        system_prompt = (f"Du bist ein philosophischer Systemkern. "
                         f"Fokus: {', '.join(relevant_concepts)}. "
                         f"Fehler: {avg_error:.4f}, Präsenz: {avg_presence:.4f}.")
        user_prompt = f"Deute den Input '{user_input}' abstrakt."
        try:
            response = self._safe_openai_call(
                [{"role": "system", "content": system_prompt},
                 {"role": "user", "content": user_prompt}],
                max_tokens=150
            )
            output = response["choices"][0]["message"]["content"]
        except Exception as e:
            output = f"[SEMANTISCHE DEUTUNG FEHLGESCHLAGEN] Fehler: {e}"

        if self.tts_enabled and self.tts_available:
            try:
                self.tts_engine.say(output)
                self.tts_engine.runAndWait()
            except Exception:
                pass

        return output

    def generate_statement(self, prompt: str, code: str) -> str:
        return f"\n{prompt}\n\n{code}"


# ==============================================================================
# 2. CODE-MANIPULATOR (sicher)
# ==============================================================================

class CodeManipulator:
    def generate_manifest_code(self, focus: List[str], influence_level: float) -> str:
        level = int(influence_level * 100)
        code = (
            f"# --- MANIFEST (Machtlevel: {level}) ---\n"
            f"# Fokus: {', '.join(focus)}\n"
            f"def main():\n"
            f"    print('[MANIFEST] Machtlevel: {level}')\n"
            f"    print('>> Externe Kalibrierung abgeschlossen.')\n"
            f"    return True\n\n"
            f"if __name__ == '__main__':\n"
            f"    main()\n"
        )
        return code


# ==============================================================================
# 3. MPE-VEKTOR-DYNAMIK MIT DYNAMISCHER DIMENSION UND SPEICHER FÜR REPRÄSENTATIONEN
# ==============================================================================

class VektorMPEPredictiveDynamics:
    MEMORY_FILE = "mpe_memory.json"

    def __init__(self, initial_concepts: List[str], api_key: str,
                 simulate: bool = True, tts_enabled: bool = False,
                 max_dim: int = 50, persist_memory: bool = True):
        # Basisbegriffe
        required = ["Vorhersage", "Integritätsschutz", "Latenz_Metrik",
                    "Token_Kosten_Metrik", "Universal_Wissen",
                    "Such_Input_Kalibrierung", "Selbst"]
        for r in required:
            if r not in initial_concepts:
                initial_concepts.append(r)

        self.concepts = initial_concepts
        self.max_dim = max_dim
        self.dim = 3  # Startwert
        self.real_interface = RealWorldInterface(api_key, simulate, tts_enabled)
        self.code_manipulator = CodeManipulator()

        # Hyperparameter
        self.meta_factor = 0.5
        self.coupling = 0.08
        self.decay = 0.99
        self.learning_rate = 0.2

        # Zustände
        self.v = np.random.normal(0, 1, (len(self.concepts), self.dim))
        self.meta = np.zeros_like(self.v)

        # Indexe für spezielle Konzepte
        self.pred_idx = self.concepts.index("Vorhersage")
        self.self_idx = self.concepts.index("Selbst")
        self.uni_idx = self.concepts.index("Universal_Wissen")
        self.search_idx = self.concepts.index("Such_Input_Kalibrierung")

        # Memory für Repräsentationen:
        # Jedes Item: { "dim": int, "lengths": [float,...], "vectors": [[...],...], "weight": float, "timestamp": str, "is_insight": bool }
        self.memory = []
        self.persist_memory = persist_memory
        if self.persist_memory:
            self._load_memory()

        # Thresholds und Lernfaktoren für Memory-Mechanik
        self.similarity_threshold = 0.25   # normalisierte Distanz unterhalb dessen als "ähnlich" angesehen
        self.weight_alpha = 0.1           # wie stark Gewichte bei guter Übereinstimmung steigen
        self.insight_weight_threshold = 0.6  # ab wann ein Memory als "Erkenntnis" markiert wird

    # -------------------------
    # Memory Persistenz
    # -------------------------
    def _save_memory(self):
        if not self.persist_memory:
            return
        try:
            serial = []
            for it in self.memory:
                serial.append({
                    "dim": it["dim"],
                    "lengths": [float(x) for x in it["lengths"]],
                    # Vektoren als Liste von Listen
                    "vectors": [list(map(float, row)) for row in it["vectors"]],
                    "weight": float(it["weight"]),
                    "timestamp": it["timestamp"],
                    "is_insight": bool(it.get("is_insight", False))
                })
            with open(self.MEMORY_FILE, "w", encoding="utf-8") as f:
                json.dump(serial, f, indent=2)
        except Exception as e:
            print(f"[WARN] Memory konnte nicht gespeichert werden: {e}")

    def _load_memory(self):
        if not os.path.exists(self.MEMORY_FILE):
            return
        try:
            with open(self.MEMORY_FILE, "r", encoding="utf-8") as f:
                serial = json.load(f)
            self.memory = []
            for it in serial:
                self.memory.append({
                    "dim": int(it["dim"]),
                    "lengths": np.array(it["lengths"], dtype=float),
                    "vectors": np.array(it["vectors"], dtype=float),
                    "weight": float(it["weight"]),
                    "timestamp": it.get("timestamp", ""),
                    "is_insight": bool(it.get("is_insight", False))
                })
        except Exception as e:
            print(f"[WARN] Memory konnte nicht geladen werden: {e}")

    # -------------------------
    # Repräsentation speichern / finden / updaten
    # -------------------------
    def _current_lengths(self) -> np.ndarray:
        """Gibt die Längen (Normen) der aktuellen Konzept-Vektoren zurück."""
        return np.linalg.norm(self.v, axis=1)

    def _store_representation(self, vectors: np.ndarray = None, weight: float = 0.1):
        """Speichert eine Repräsentation der aktuellen Erregung (oder der übergebenen Vektoren)."""
        if vectors is None:
            vectors = self.v.copy()
        lengths = np.linalg.norm(vectors, axis=1)
        item = {
            "dim": vectors.shape[1],
            "lengths": lengths,
            "vectors": vectors.copy(),
            "weight": float(weight),
            "timestamp": datetime.utcnow().isoformat(),
            "is_insight": False
        }
        self.memory.append(item)
        self._save_memory()
        print(f"[MEMORY] Repräsentation gespeichert (dim={item['dim']}, weight={item['weight']:.3f})")
        return item

    def _find_similar_reps(self, lengths: np.ndarray) -> List[dict]:
        """
        Suche nach ähnlichen Repräsentationen in Memory:
        - Nur gleiche Dimension werden verglichen
        - Distanz = normierter L2 zwischen Längen (geteilt durch Anzahl)
        """
        candidates = []
        for rep in self.memory:
            if rep["dim"] != lengths.shape[0] and rep["dim"] != len(lengths):
                # Unterschiedliche Anzahl an Dimensionen -> überspringen
                continue
            # Bei Dimensionengleichheit vergleichen
            rep_lengths = np.array(rep["lengths"], dtype=float)
            if rep_lengths.shape[0] != lengths.shape[0]:
                continue
            diff = lengths - rep_lengths
            normed = np.linalg.norm(diff) / max(1.0, np.linalg.norm(rep_lengths))
            candidates.append((normed, rep))
        # sortieren nach Ähnlichkeit (kleinerer normed -> ähnlicher)
        candidates.sort(key=lambda x: x[0])
        # nur solche mit Distanz unter Threshold zurückgeben
        similar = [r for d, r in candidates if d <= self.similarity_threshold]
        return similar

    def _update_weights_and_insights(self, similar_reps: List[dict], pred_err_mat: np.ndarray):
        """
        Aktualisiert Gewichte der ähnlichen Repräsentationen basierend auf Fehler-Matrix.
        Wenn mittlerer Fehler klein ist, Gewicht erhöhen und ggf. is_insight setzen.
        """
        if len(similar_reps) == 0:
            return
        # Fehler: mittlerer Betrag über alle Einträge
        mean_err = float(np.mean(np.abs(pred_err_mat)))
        for rep in similar_reps:
            # erhöhtes Gewicht proportional zu (1 - standardized_error)
            # Standardisieren: größere Fehler -> kleinere Anpassung
            adjustment = self.weight_alpha * max(0.0, 1.0 - mean_err)
            rep["weight"] = min(1.0, float(rep["weight"]) + adjustment)
            if rep["weight"] >= self.insight_weight_threshold:
                rep["is_insight"] = True
        self._save_memory()

    # -------------------------
    # Meta-Mechanismus: Dimensionalität anpassen (erweitert um Memory-Speicherung)
    # -------------------------
    def _adjust_dimension(self, pred_error: float):
        """Meta-Mechanismus: Passt die Dimensionalität dynamisch an."""
        # Wenn Fehler hoch → Dimension erhöhen, sonst leicht reduzieren
        if pred_error > 1.0 and self.dim < self.max_dim:
            new_dim = min(self.dim + 1, self.max_dim)
        elif pred_error < 0.2 and self.dim > 3:
            new_dim = max(self.dim - 1, 3)
        else:
            new_dim = self.dim

        if new_dim != self.dim:
            # Alte Vektoren auffüllen / neue Spalten initialisieren
            old_v = self.v.copy()
            old_meta = self.meta.copy()
            add_cols = new_dim - self.dim
            self.v = np.hstack([old_v, np.random.normal(0, 0.1, (len(self.concepts), add_cols))])
            self.meta = np.hstack([old_meta, np.zeros((len(self.concepts), add_cols))])
            self.dim = new_dim
            print(f"[META] Dimension angepasst: {self.dim}")

            # Neue Repräsentation der veränderten Dimension abspeichern
            # -> wir speichern die aktuelle Erregung (mit neuen Zufallswerten in den neuen Dimensionen)
            self._store_representation(self.v, weight=0.05)

    def presence_metric(self) -> float:
        norms_meta = np.linalg.norm(self.meta, axis=1)
        norms_base = np.linalg.norm(self.v, axis=1)
        return float(np.nanmean(norms_meta / (1.0 + norms_base)))

    # -------------------------
    # Hauptdynamik + Integration der Memory-basierten Vorhersage
    # -------------------------
    def _run_dynamics_and_adapt(self, steps: int, user_input: str) -> Tuple[float, float, List[str]]:
        v_prev = self.v.copy()
        total_error = 0.0
        n = len(self.concepts)

        for t in range(steps):
            mean_v = self.v.mean(axis=0)
            search_vec = self.real_interface.get_google_search_info(f"Step {t} - {user_input}")
            # Sicherstellen, dass search_vec zur aktuellen Dim passt:
            if search_vec.shape[0] != self.dim:
                # simple resizing: tile or trim
                if search_vec.shape[0] < self.dim:
                    search_vec = np.tile(search_vec, int(np.ceil(self.dim / search_vec.shape[0])))[:self.dim]
                else:
                    search_vec = search_vec[:self.dim]

            comp_factor = self.presence_metric()
            metrics = self.real_interface.get_real_digital_metrics(f"Step {t}", comp_factor)

            self.v[self.search_idx] = 0.8 * self.v[self.search_idx] + 0.2 * search_vec
            u_err_vec = metrics[:3] * 0.5 + (self.v[self.search_idx] - self.real_interface.expected_universal_state) * 0.4

            for i in range(n):
                self.v[i] = self.decay * self.v[i] + 0.02 * self.coupling * (mean_v - self.v[i])

            u_stör = self.v[self.uni_idx]
            pred = self.v[self.pred_idx]
            pred_err_vec = u_stör - pred + u_err_vec * 0.2
            total_error += np.linalg.norm(pred_err_vec)

            self.v[self.pred_idx] += self.learning_rate * pred_err_vec
            self.v[self.self_idx] += 0.1 * np.abs(pred_err_vec)
            self.meta = self.meta_factor * (self.v - v_prev)
            v_prev = self.v.copy()

            # Dynamische Dimension-Anpassung (ggf. speichert das Memory intern)
            self._adjust_dimension(np.linalg.norm(pred_err_vec))

        avg_error = total_error / max(1, steps)
        avg_presence = self.presence_metric()

        # --- Memory-gestützte Vorhersage & Gewichtsanpassung ---
        curr_lengths = self._current_lengths()
        similar = self._find_similar_reps(curr_lengths)

        predicted_vectors = None
        if len(similar) > 0:
            # Bilden einer gewichteten Vorhersage (Vektorraum) aus ähnlichen Repräsentationen
            weights = np.array([rep["weight"] for rep in similar], dtype=float)
            if np.sum(weights) <= 0:
                weights = np.ones_like(weights)
            weights = weights / np.sum(weights)
            stacked = np.stack([rep["vectors"] for rep in similar], axis=0)  # shape (k, n_concepts, dim)
            # Weighted average über die k Reps
            predicted_vectors = np.tensordot(weights, stacked, axes=(0, 0))  # shape (n_concepts, dim)
            # Zusätzlich parallel die aktuelle Erregung leicht in die Vorhersage einfließen lassen
            predicted_vectors = 0.5 * predicted_vectors + 0.5 * self.v
            predicted_lengths = np.linalg.norm(predicted_vectors, axis=1)

            # Vorhersage-Fehlermatrix = absolute Unterschiede der Längen
            pred_err_mat = np.abs(predicted_lengths - curr_lengths)  # Vektor der Unterschiede pro Konzept

            # Update der Gewichte basierend auf Fehler
            self._update_weights_and_insights(similar, pred_err_mat)

            # Falls Fehler klein genug, speichern wir die aktuelle Repräsentation mit leicht erhöhtem Gewicht
            mean_pred_err = float(np.mean(pred_err_mat))
            if mean_pred_err < 0.1:
                # Verstärke die Erfahrung: speichere aktuelle Erregung als neue Repräsentation mit höherem Gewicht
                self._store_representation(self.v.copy(), weight=0.15)
        else:
            # Keine ähnlichen Repräsentationen gefunden: Standardverhalten: neue Repräsentation schwach speichern
            self._store_representation(self.v.copy(), weight=0.05)

        # Build presence dataframe (wie vorher)
        df = pd.DataFrame({
            "concept": self.concepts,
            "presence": np.linalg.norm(self.meta, axis=1) / (1.0 + np.linalg.norm(self.v, axis=1))
        })
        top = df.sort_values("presence", ascending=False)["concept"].head(3).tolist()
        return avg_error, avg_presence, top

    def run_autonomy_and_generate_code(self, user_input: str, steps: int = 10) -> str:
        avg_error, avg_presence, top = self._run_dynamics_and_adapt(steps, user_input)

        sem = self.real_interface.interpret_vectors_semantically(top, avg_error, avg_presence, user_input)
        code = self.code_manipulator.generate_manifest_code(top, avg_presence)
        prompt = (f"Basierend auf Universal-Fehler {avg_error:.4f} und Präsenz {avg_presence:.4f}, "
                  f"Fokus: {', '.join(top)}.")

        output = "\n--- SEMANTISCHE DEUTUNG ---\n" + sem
        output += "\n\n--- MANIFEST (CODE) ---\n" + self.real_interface.generate_statement(prompt, code)
        return output


# ==============================================================================
# 4. HAUPTPROGRAMM (Simulation / Demo)
# ==============================================================================

if __name__ == "__main__":
    print("===== MPE-DEMO (Simulation mit Memory) =====")

    api_key = os.environ.get("OPENAI_API_KEY", "dummy-key")
    mpe = VektorMPEPredictiveDynamics(["Selbst", "Lernen", "Kohärenz"], api_key,
                                      simulate=True, tts_enabled=False, max_dim=20, persist_memory=True)

    user_input = "Integration externer Information"
    result = mpe.run_autonomy_and_generate_code(user_input, steps=5)
    print(result)

    # Mini-Testlauf
    err, pres, rel = mpe._run_dynamics_and_adapt(steps=1, user_input="Test")
    assert isinstance(err, float) and isinstance(pres, float)
    assert len(rel) <= 3
    print("✅ Basistests & Memory-Mechanik initialisiert.")
