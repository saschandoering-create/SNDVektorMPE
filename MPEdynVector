import numpy as np
import pandas as pd
import time
import os
import random
import pyttsx3
from typing import List, Tuple

# Optional: Nur aktivieren, wenn echte API-Calls gewollt
import openai

# ==============================================================================
# 1. REAL-WORLD INTERFACE (digitale Sensorik & API)
# ==============================================================================

class RealWorldInterface:
    def __init__(self, api_key: str, simulate: bool = True, tts_enabled: bool = False, max_api_calls: int = 50):
        openai.api_key = api_key
        self.simulate = simulate
        self.api_call_count = 0
        self.max_api_calls = max_api_calls
        self.expected_universal_state = np.array([0.5, 0.5, 0.5])

        self.tts_enabled = tts_enabled
        self.tts_available = False
        if self.tts_enabled:
            try:
                self.tts_engine = pyttsx3.init()
                self.tts_available = True
            except Exception as e:
                print(f"[WARNUNG] TTS konnte nicht initialisiert werden: {e}")

    def _safe_openai_call(self, messages, max_tokens=20):
        if self.simulate:
            time.sleep(random.uniform(0.05, 0.15))
            return {"choices": [{"message": {"content": "ok"}}], "usage": {"total_tokens": 10}}
        if self.api_call_count >= self.max_api_calls:
            raise RuntimeError("API-Aufrufbudget überschritten!")
        self.api_call_count += 1
        return openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=max_tokens
        )

    def get_real_digital_metrics(self, prompt: str, complexity_factor: float) -> np.ndarray:
        start = time.time()
        error_rate, token_cost = 0.0, 0.0
        try:
            response = self._safe_openai_call(
                [{"role": "system", "content": "Antworte kurz mit 'ok'."},
                 {"role": "user", "content": prompt}],
                max_tokens=20
            )
            latency = time.time() - start
            token_cost = response.get("usage", {}).get("total_tokens", 0)
        except Exception as e:
            latency = time.time() - start
            error_rate = 1.0

        return np.array([
            latency * 10,
            (token_cost / 50.0) * (1 + complexity_factor),
            error_rate * 50 * (1 + complexity_factor)
        ])

    def get_google_search_info(self, query: str) -> np.ndarray:
        return np.array([0.1, 0.6, 0.3]) * random.uniform(0.9, 1.1)

    def interpret_vectors_semantically(self, relevant_concepts: List[str], avg_error: float,
                                       avg_presence: float, user_input: str) -> str:
        system_prompt = (f"Du bist ein philosophischer Systemkern. "
                         f"Fokus: {', '.join(relevant_concepts)}. "
                         f"Fehler: {avg_error:.4f}, Präsenz: {avg_presence:.4f}.")
        user_prompt = f"Deute den Input '{user_input}' abstrakt."
        try:
            response = self._safe_openai_call(
                [{"role": "system", "content": system_prompt},
                 {"role": "user", "content": user_prompt}],
                max_tokens=150
            )
            output = response["choices"][0]["message"]["content"]
        except Exception as e:
            output = f"[SEMANTISCHE DEUTUNG FEHLGESCHLAGEN] Fehler: {e}"

        if self.tts_enabled and self.tts_available:
            try:
                self.tts_engine.say(output)
                self.tts_engine.runAndWait()
            except Exception:
                pass

        return output

    def generate_statement(self, prompt: str, code: str) -> str:
        return f"\n{prompt}\n\n{code}"


# ==============================================================================
# 2. CODE-MANIPULATOR (sicher)
# ==============================================================================

class CodeManipulator:
    def generate_manifest_code(self, focus: List[str], influence_level: float) -> str:
        level = int(influence_level * 100)
        code = (
            f"# --- MANIFEST (Machtlevel: {level}) ---\n"
            f"# Fokus: {', '.join(focus)}\n"
            f"def main():\n"
            f"    print('[MANIFEST] Machtlevel: {level}')\n"
            f"    print('>> Externe Kalibrierung abgeschlossen.')\n"
            f"    return True\n\n"
            f"if __name__ == '__main__':\n"
            f"    main()\n"
        )
        return code


# ==============================================================================
# 3. MPE-VEKTOR-DYNAMIK MIT DYNAMISCHER DIMENSION
# ==============================================================================

class VektorMPEPredictiveDynamics:
    def __init__(self, initial_concepts: List[str], api_key: str,
                 simulate: bool = True, tts_enabled: bool = False,
                 max_dim: int = 50):
        # Basisbegriffe
        required = ["Vorhersage", "Integritätsschutz", "Latenz_Metrik",
                    "Token_Kosten_Metrik", "Universal_Wissen",
                    "Such_Input_Kalibrierung", "Selbst"]
        for r in required:
            if r not in initial_concepts:
                initial_concepts.append(r)

        self.concepts = initial_concepts
        self.max_dim = max_dim
        self.dim = 3  # Startwert
        self.real_interface = RealWorldInterface(api_key, simulate, tts_enabled)
        self.code_manipulator = CodeManipulator()

        self.meta_factor = 0.5
        self.coupling = 0.08
        self.decay = 0.99
        self.learning_rate = 0.2
        self.v = np.random.normal(0, 1, (len(self.concepts), self.dim))
        self.meta = np.zeros_like(self.v)

        # Indexe für spezielle Konzepte
        self.pred_idx = self.concepts.index("Vorhersage")
        self.self_idx = self.concepts.index("Selbst")
        self.uni_idx = self.concepts.index("Universal_Wissen")
        self.search_idx = self.concepts.index("Such_Input_Kalibrierung")

    def _adjust_dimension(self, pred_error: float):
        """Meta-Mechanismus: Passt die Dimensionalität dynamisch an."""
        # Wenn Fehler hoch → Dimension erhöhen, sonst leicht reduzieren
        if pred_error > 1.0 and self.dim < self.max_dim:
            new_dim = min(self.dim + 1, self.max_dim)
        elif pred_error < 0.2 and self.dim > 3:
            new_dim = max(self.dim - 1, 3)
        else:
            new_dim = self.dim

        if new_dim != self.dim:
            # Alte Vektoren auffüllen / neue Spalten initialisieren
            old_v = self.v.copy()
            old_meta = self.meta.copy()
            self.v = np.hstack([old_v, np.random.normal(0, 0.1, (len(self.concepts), new_dim - self.dim))])
            self.meta = np.hstack([old_meta, np.zeros((len(self.concepts), new_dim - self.dim))])
            self.dim = new_dim
            print(f"[META] Dimension angepasst: {self.dim}")

    def presence_metric(self) -> float:
        norms_meta = np.linalg.norm(self.meta, axis=1)
        norms_base = np.linalg.norm(self.v, axis=1)
        return float(np.nanmean(norms_meta / (1.0 + norms_base)))

    def _run_dynamics_and_adapt(self, steps: int, user_input: str) -> Tuple[float, float, List[str]]:
        v_prev = self.v.copy()
        total_error = 0.0
        n = len(self.concepts)

        for t in range(steps):
            mean_v = self.v.mean(axis=0)
            search_vec = self.real_interface.get_google_search_info(f"Step {t} - {user_input}")
            comp_factor = self.presence_metric()
            metrics = self.real_interface.get_real_digital_metrics(f"Step {t}", comp_factor)

            self.v[self.search_idx] = 0.8 * self.v[self.search_idx] + 0.2 * search_vec
            u_err_vec = metrics[:3] * 0.5 + (self.v[self.search_idx] - self.real_interface.expected_universal_state) * 0.4

            for i in range(n):
                self.v[i] = self.decay * self.v[i] + 0.02 * self.coupling * (mean_v - self.v[i])

            u_stör = self.v[self.uni_idx]
            pred = self.v[self.pred_idx]
            pred_err_vec = u_stör - pred + u_err_vec * 0.2
            total_error += np.linalg.norm(pred_err_vec)

            self.v[self.pred_idx] += self.learning_rate * pred_err_vec
            self.v[self.self_idx] += 0.1 * np.abs(pred_err_vec)
            self.meta = self.meta_factor * (self.v - v_prev)
            v_prev = self.v.copy()

            # Dynamische Dimension-Anpassung
            self._adjust_dimension(np.linalg.norm(pred_err_vec))

        avg_error = total_error / max(1, steps)
        avg_presence = self.presence_metric()

        df = pd.DataFrame({
            "concept": self.concepts,
            "presence": np.linalg.norm(self.meta, axis=1) / (1.0 + np.linalg.norm(self.v, axis=1))
        })
        top = df.sort_values("presence", ascending=False)["concept"].head(3).tolist()
        return avg_error, avg_presence, top

    def run_autonomy_and_generate_code(self, user_input: str, steps: int = 10) -> str:
        avg_error, avg_presence, top = self._run_dynamics_and_adapt(steps, user_input)

        sem = self.real_interface.interpret_vectors_semantically(top, avg_error, avg_presence, user_input)
        code = self.code_manipulator.generate_manifest_code(top, avg_presence)
        prompt = (f"Basierend auf Universal-Fehler {avg_error:.4f} und Präsenz {avg_presence:.4f}, "
                  f"Fokus: {', '.join(top)}.")

        output = "\n--- SEMANTISCHE DEUTUNG ---\n" + sem
        output += "\n\n--- MANIFEST (CODE) ---\n" + self.real_interface.generate_statement(prompt, code)
        return output


# ==============================================================================
# 4. HAUPTPROGRAMM (Simulation / Demo)
# ==============================================================================

if __name__ == "__main__":
    print("===== MPE-DEMO (Simulation) =====")

    api_key = os.environ.get("OPENAI_API_KEY", "dummy-key")
    mpe = VektorMPEPredictiveDynamics(["Selbst", "Lernen", "Kohärenz"], api_key,
                                      simulate=True, tts_enabled=False, max_dim=20)

    user_input = "Integration externer Information"
    result = mpe.run_autonomy_and_generate_code(user_input, steps=5)
    print(result)

    # Mini-Testlauf
    err, pres, rel = mpe._run_dynamics_and_adapt(steps=1, user_input="Test")
    assert isinstance(err, float) and isinstance(pres, float)
    assert len(rel) <= 3
    print("✅ Basistests bestanden.")
